{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de Texto con Búsqueda Greedy (Greedy Search) usando GPT-2\n",
    "\n",
    "GPT-2 es un modelo con una arquitectura **decoder-only** (solo decodificador), lo que significa que está diseñado para predecir el siguiente token en una secuencia basándose en los tokens anteriores. Es inherentemente adecuado para tareas de generación de texto a partir de un *prompt* o contexto inicial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Carga del Modelo y Tokenizador\n",
    "\n",
    "Primero, cargamos el modelo y el tokenizador necesarios desde la librería `transformers` de Hugging Face:\n",
    "\n",
    "* devive: Nos aseguramos que estemos usando el poder computacional de nuestra GPU ;p\n",
    "* model: Modelo preentrenado, en este caso usaremos un modelo preentrado `gpt2-xl`\n",
    "* tokenizer: Tokenizador para nuestro modelo, se ajusta segun el modelo seleccionado\n",
    "\n",
    "ref: https://huggingface.co/docs/transformers/v4.51.3/en/model_doc/auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"gpt2-xl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2-xl', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Greedy Search Decoding --> torch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.greedy_search import greedy_search_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>'m (9.32%)</td>\n",
       "      <td>think (6.08%)</td>\n",
       "      <td>am (4.13%)</td>\n",
       "      <td>have (3.90%)</td>\n",
       "      <td>don (3.75%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm</td>\n",
       "      <td>not (17.84%)</td>\n",
       "      <td>going (5.71%)</td>\n",
       "      <td>a (5.38%)</td>\n",
       "      <td>sure (3.83%)</td>\n",
       "      <td>sorry (3.70%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not</td>\n",
       "      <td>sure (13.76%)</td>\n",
       "      <td>going (11.80%)</td>\n",
       "      <td>a (8.03%)</td>\n",
       "      <td>saying (7.66%)</td>\n",
       "      <td>trying (2.16%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm not sure</td>\n",
       "      <td>if (15.01%)</td>\n",
       "      <td>what (13.82%)</td>\n",
       "      <td>how (10.56%)</td>\n",
       "      <td>I (8.58%)</td>\n",
       "      <td>that (6.73%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm not sure if</td>\n",
       "      <td>I (14.76%)</td>\n",
       "      <td>it (13.96%)</td>\n",
       "      <td>you (12.76%)</td>\n",
       "      <td>this (10.01%)</td>\n",
       "      <td>the (6.76%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm not sure if I</td>\n",
       "      <td>'m (20.09%)</td>\n",
       "      <td>can (10.83%)</td>\n",
       "      <td>'ll (7.12%)</td>\n",
       "      <td>should (7.07%)</td>\n",
       "      <td>'ve (6.32%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm not sure if I'm</td>\n",
       "      <td>going (9.95%)</td>\n",
       "      <td>a (4.82%)</td>\n",
       "      <td>the (4.74%)</td>\n",
       "      <td>ready (4.09%)</td>\n",
       "      <td>supposed (4.02%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm not sure if I'm going</td>\n",
       "      <td>to (96.20%)</td>\n",
       "      <td>through (0.27%)</td>\n",
       "      <td>back (0.27%)</td>\n",
       "      <td>too (0.25%)</td>\n",
       "      <td>crazy (0.25%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Input        Choice 1          Choice 2       Choice 3  \\\n",
       "0                          I      'm (9.32%)     think (6.08%)     am (4.13%)   \n",
       "1                        I'm    not (17.84%)     going (5.71%)      a (5.38%)   \n",
       "2                    I'm not   sure (13.76%)    going (11.80%)      a (8.03%)   \n",
       "3               I'm not sure     if (15.01%)     what (13.82%)   how (10.56%)   \n",
       "4            I'm not sure if      I (14.76%)       it (13.96%)   you (12.76%)   \n",
       "5          I'm not sure if I     'm (20.09%)      can (10.83%)    'll (7.12%)   \n",
       "6        I'm not sure if I'm   going (9.95%)         a (4.82%)    the (4.74%)   \n",
       "7  I'm not sure if I'm going     to (96.20%)   through (0.27%)   back (0.27%)   \n",
       "\n",
       "          Choice 4           Choice 5  \n",
       "0     have (3.90%)        don (3.75%)  \n",
       "1     sure (3.83%)      sorry (3.70%)  \n",
       "2   saying (7.66%)     trying (2.16%)  \n",
       "3        I (8.58%)       that (6.73%)  \n",
       "4    this (10.01%)        the (6.76%)  \n",
       "5   should (7.07%)        've (6.32%)  \n",
       "6    ready (4.09%)   supposed (4.02%)  \n",
       "7      too (0.25%)      crazy (0.25%)  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_txt = \"I\"\n",
    "iterations = greedy_search_generation(model, tokenizer, input_txt)\n",
    "df = pd.DataFrame(iterations)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Input': \"I'm not sure if I'm going\",\n",
       " 'Choice 1': ' to (96.20%)',\n",
       " 'Choice 2': ' through (0.27%)',\n",
       " 'Choice 3': ' back (0.27%)',\n",
       " 'Choice 4': ' too (0.25%)',\n",
       " 'Choice 5': ' crazy (0.25%)'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In a shocking finding, scientist discovered a ...</td>\n",
       "      <td>The (29.40%)</td>\n",
       "      <td>\" (7.33%)</td>\n",
       "      <td>According (4.11%)</td>\n",
       "      <td>In (2.38%)</td>\n",
       "      <td>A (1.94%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a shocking finding, scientist discovered a ...</td>\n",
       "      <td>researchers (9.20%)</td>\n",
       "      <td>discovery (6.21%)</td>\n",
       "      <td>scientists (5.67%)</td>\n",
       "      <td>herd (3.55%)</td>\n",
       "      <td>unic (3.12%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In a shocking finding, scientist discovered a ...</td>\n",
       "      <td>, (12.27%)</td>\n",
       "      <td>were (8.31%)</td>\n",
       "      <td>believe (5.64%)</td>\n",
       "      <td>from (5.59%)</td>\n",
       "      <td>found (3.50%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In a shocking finding, scientist discovered a ...</td>\n",
       "      <td>from (27.48%)</td>\n",
       "      <td>who (16.70%)</td>\n",
       "      <td>led (16.54%)</td>\n",
       "      <td>Dr (3.07%)</td>\n",
       "      <td>a (1.64%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In a shocking finding, scientist discovered a ...</td>\n",
       "      <td>the (62.88%)</td>\n",
       "      <td>Argentina (1.19%)</td>\n",
       "      <td>University (0.99%)</td>\n",
       "      <td>Columbia (0.85%)</td>\n",
       "      <td>Arizona (0.81%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>In a shocking finding, scientist discovered a ...</td>\n",
       "      <td>to (97.53%)</td>\n",
       "      <td>that (0.80%)</td>\n",
       "      <td>by (0.59%)</td>\n",
       "      <td>at (0.27%)</td>\n",
       "      <td>when (0.24%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>In a shocking finding, scientist discovered a ...</td>\n",
       "      <td>find (99.49%)</td>\n",
       "      <td>learn (0.19%)</td>\n",
       "      <td>see (0.16%)</td>\n",
       "      <td>discover (0.05%)</td>\n",
       "      <td>finding (0.02%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>In a shocking finding, scientist discovered a ...</td>\n",
       "      <td>that (97.64%)</td>\n",
       "      <td>the (1.04%)</td>\n",
       "      <td>unic (0.39%)</td>\n",
       "      <td>a (0.26%)</td>\n",
       "      <td>out (0.11%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>In a shocking finding, scientist discovered a ...</td>\n",
       "      <td>the (97.43%)</td>\n",
       "      <td>unic (0.80%)</td>\n",
       "      <td>they (0.34%)</td>\n",
       "      <td>there (0.14%)</td>\n",
       "      <td>, (0.13%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>In a shocking finding, scientist discovered a ...</td>\n",
       "      <td>unic (97.54%)</td>\n",
       "      <td>unicorn (1.71%)</td>\n",
       "      <td>Unic (0.47%)</td>\n",
       "      <td>animals (0.02%)</td>\n",
       "      <td>Unicorn (0.01%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Input              Choice 1  \\\n",
       "0    In a shocking finding, scientist discovered a ...          The (29.40%)   \n",
       "1    In a shocking finding, scientist discovered a ...   researchers (9.20%)   \n",
       "2    In a shocking finding, scientist discovered a ...            , (12.27%)   \n",
       "3    In a shocking finding, scientist discovered a ...         from (27.48%)   \n",
       "4    In a shocking finding, scientist discovered a ...          the (62.88%)   \n",
       "..                                                 ...                   ...   \n",
       "123  In a shocking finding, scientist discovered a ...           to (97.53%)   \n",
       "124  In a shocking finding, scientist discovered a ...         find (99.49%)   \n",
       "125  In a shocking finding, scientist discovered a ...         that (97.64%)   \n",
       "126  In a shocking finding, scientist discovered a ...          the (97.43%)   \n",
       "127  In a shocking finding, scientist discovered a ...         unic (97.54%)   \n",
       "\n",
       "               Choice 2             Choice 3           Choice 4  \\\n",
       "0             \" (7.33%)    According (4.11%)         In (2.38%)   \n",
       "1     discovery (6.21%)   scientists (5.67%)       herd (3.55%)   \n",
       "2          were (8.31%)      believe (5.64%)       from (5.59%)   \n",
       "3          who (16.70%)         led (16.54%)         Dr (3.07%)   \n",
       "4     Argentina (1.19%)   University (0.99%)   Columbia (0.85%)   \n",
       "..                  ...                  ...                ...   \n",
       "123        that (0.80%)           by (0.59%)         at (0.27%)   \n",
       "124       learn (0.19%)          see (0.16%)   discover (0.05%)   \n",
       "125         the (1.04%)         unic (0.39%)          a (0.26%)   \n",
       "126        unic (0.80%)         they (0.34%)      there (0.14%)   \n",
       "127     unicorn (1.71%)         Unic (0.47%)    animals (0.02%)   \n",
       "\n",
       "             Choice 5  \n",
       "0           A (1.94%)  \n",
       "1        unic (3.12%)  \n",
       "2       found (3.50%)  \n",
       "3           a (1.64%)  \n",
       "4     Arizona (0.81%)  \n",
       "..                ...  \n",
       "123      when (0.24%)  \n",
       "124   finding (0.02%)  \n",
       "125       out (0.11%)  \n",
       "126         , (0.13%)  \n",
       "127   Unicorn (0.01%)  \n",
       "\n",
       "[128 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = 128\n",
    "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
    "a herd of unicorns living in a remote, previously unexplored \\\n",
    "valley, in the Andes Mountains. Even more surprising to the \\\n",
    "researchers was the fact that the unicorns spoke perfect English.\\n\\n\n",
    "\"\"\"\n",
    "iterations = greedy_search_generation(model, tokenizer, input_txt, n_steps=n_steps)\n",
    "df = pd.DataFrame(iterations)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\\n\\n\\nThe researchers, from the University of California, Davis, and the University of Colorado, Boulder, were conducting a study on the Andean cloud forest, which is home to the rare species of cloud forest trees.\\n\\n\\nThe researchers were surprised to find that the unicorns were able to communicate with each other, and even with humans.\\n\\n\\nThe researchers were surprised to find that the unicorns were able to communicate with each other, and even with humans.\\n\\nThe researchers were surprised to find that the unicorns were able to communicate with each other, and even with humans.\\n\\nThe researchers were surprised to find that the'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostrar el último paso\n",
    "df.iloc[-1]['Input']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
